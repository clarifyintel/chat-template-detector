model: gpt-3.5-turbo
temperature: 0.7
max_tokens: 512
chat_template: "<|im_start|>{role}\n{content}<|im_end|>"
